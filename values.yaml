# BD SelfScan Enhanced Configuration Values with Per-Application Policy Gating
# This file contains enhanced configuration values for the BD SelfScan Helm chart
# Includes security best practices and DevSecOps improvements with per-application policy enforcement
#
# Global configuration
global:
  namespace: "bd-selfscan-system"

# Chart metadata
nameOverride: ""
fullnameOverride: ""

# Container registry configuration
registry:
  imagePullSecrets: []
  # Optional: Configure private registry authentication
  # imagePullSecrets:
  #   - name: "private-registry-secret"
  #   - name: "docker-hub-secret"

# RBAC configuration
rbac:
  create: true
  # Use cluster-wide permissions (required for multi-namespace scanning)
  clusterRole: true
  serviceAccount:
    create: true
    name: ""
    annotations: {}

# Black Duck configuration
blackduck:
  tokenSecretName: "blackduck-creds"
  trustCert: true
  connectionTimeout: 120
  readTimeout: 300
  # Additional Black Duck settings
  verifySsl: false  # Set to true in production with proper certificates
  apiVersion: "2023.7.0"  # Specify API version for compatibility

# On-demand scanning configuration (Phase 1)
onDemand:
  enabled: true

# Automated scanning configuration (Phase 2)
automated:
  enabled: true
  # Controller configuration for Phase 2
  controller:
    image: "python:3.11-alpine"
    imagePullPolicy: "IfNotPresent"
    installDependencies: true
    replicas: 1
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"
    
    # Controller behavior settings
    scanJobTimeout: 3600
    maxConcurrentScans: 5
    cleanupInterval: 3600
    configReloadInterval: 600
    
    # Network policy configuration
    networkPolicy:
      enabled: false
    
    # Node selection
    nodeSelector: {}
    tolerations: []
    affinity: {}
  
  # Scheduled scanning configuration
  scheduled:
    enabled: false
    failedJobsHistoryLimit: 3
    successfulJobsHistoryLimit: 1
    startingDeadlineSeconds: 300

# Scan target (for on-demand scanning)
scanTarget: ""

# Application configuration - can be provided via values or file
# When provided here, these override the configs/applications.yaml file
# Example applications with per-application policy gating:
applications: []
  # - name: "Production API"
  #   namespace: "production"
  #   labelSelector: "app=api-gateway"
  #   policyGating: true                    # Enable policy enforcement
  #   policyGatingRisk: "BLOCKER,CRITICAL" # Fail on these severities
  #   projectGroup: "Production Services"
  #   projectTier: 1
  #   projectPhase: "RELEASED"
  #   description: "Critical production API with strict enforcement"
  # 
  # - name: "Development Tools"
  #   namespace: "dev-tools"
  #   labelSelector: "app=dev-dashboard"
  #   policyGating: false                   # Discovery mode
  #   policyGatingRisk: ""                  # Ignored when gating disabled
  #   projectGroup: "Development Tools"
  #   projectTier: 4
  #   projectPhase: "DEVELOPMENT"
  #   description: "Development tools in discovery mode"

# ConfigMap configuration
configMap:
  applications:
    name: "bd-selfscan-applications"

# Scanner configuration with enhanced security
scanner:
  image: "ghcr.io/snps-steve/bd-selfscan/bd-selfscan:latest"
  imagePullPolicy: "Always"  # Changed to Always to ensure latest image with unzip fix

  # Resource limits and requests - optimized for performance and security
  resources:
    requests:
      memory: "2Gi"
      cpu: "500m"
      ephemeral-storage: "10Gi"
    limits:
      memory: "8Gi"
      cpu: "4"
      ephemeral-storage: "50Gi"

  # Job configuration
  job:
    backoffLimit: 3
    activeDeadlineSeconds: 3600
    ttlSecondsAfterFinished: 86400  # 24 hours
    parallelism: 1
    completions: 1

    # FIXED: Pod-level security context - properly configured for Black Duck scanning
    securityContext:
      # Black Duck requires root privileges for container operations
      runAsNonRoot: false    # Must be false for BD scanning
      runAsUser: 0           # Root user required
      runAsGroup: 0          # Root group
      fsGroup: 0             # File system group as root
      # Enhanced security where possible
      seccompProfile:
        type: RuntimeDefault
      supplementalGroups: []

  # FIXED: Container security context - minimal privileges for BD operations
  containerSecurityContext:
    # Essential for Black Duck container scanning
    allowPrivilegeEscalation: true     # Required for container operations
    readOnlyRootFilesystem: false      # BD tools need write access
    runAsUser: 0                       # Override Dockerfile USER scanner
    runAsGroup: 0
    runAsNonRoot: false               # Must be false for BD scanning
    
    # Capability management - grant only what Black Duck needs
    capabilities:
      drop:
        - ALL  # Start with minimal privileges
      add:
        - CHOWN          # Change file ownership
        - DAC_OVERRIDE   # Bypass file read/write/execute permission checks
        - FOWNER         # Bypass permission checks for file operations
        - SETGID         # Set group ID
        - SETUID         # Set user ID
        # Add SYS_ADMIN only if container operations fail without it
        # - SYS_ADMIN    # Uncomment if needed for advanced container operations

  # Node selection and scheduling
  nodeSelector: {}
  tolerations: []
  affinity: {}

  # Advanced scheduling for production
  # nodeSelector:
  #   node-type: "scanner-nodes"  # Dedicated nodes for scanning workloads
  # tolerations:
  #   - key: "scanner-only"
  #     operator: "Equal"
  #     value: "true"
  #     effect: "NoSchedule"

  # Docker socket access (disable for enhanced security)
  dockerSocket:
    enabled: false  # Preferred: false for security
    # enabled: true  # Only if container inspection requires direct Docker access

# Scanning configuration with enhanced controls and per-application policy gating
scanning:
  projectTier: 3  # Default tier, can be overridden per application
  
  # REMOVED: Global policyFailSeverities setting
  # Policy enforcement is now controlled per application via:
  #   policyGating: true/false         (enable/disable enforcement)
  #   policyGatingRisk: "BLOCKER,..."  (severity levels that cause failures)
  # This provides granular control allowing different apps to have different enforcement levels

  # Performance tuning
  imageDownloadTimeout: 600
  imageDownloadRetries: 3
  scanTimeout: 1800
  maxConcurrentScans: 3
  maxConcurrentDownloads: 2

  # Cleanup and retention
  cleanupInterval: 7200
  keepSuccessfulJobs: 5
  keepFailedJobs: 10

  # Enhanced security scanning options
  enableVulnerabilityScanning: true
  enableLicenseScanning: true
  enableOperationalRisks: true

  # Policy enforcement - now managed per application
  enforceProjectTierPolicies: true
  blockDeploymentOnPolicyViolation: false  # Set to true for production enforcement

# Debug and observability configuration
debug:
  enabled: true
  logLevel: "INFO"  # DEBUG, INFO, WARNING, ERROR
  keepTempFiles: false
  enableVerboseLogging: false
  enablePerformanceMetrics: true

# Monitoring and observability
monitoring:
  enabled: true

  # Prometheus integration
  serviceMonitor:
    enabled: false  # Set to true if Prometheus operator is available
    interval: "30s"
    scrapeTimeout: "10s"
    labels: {}

  # Grafana dashboard
  grafana:
    enabled: false
    dashboardLabel: "grafana_dashboard"
    datasource: "Prometheus"

  # Health checks and probes
  healthCheck:
    enabled: true
    endpoint: "/health"
    port: 8081
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 3

# Network security configuration
networkPolicy:
  enabled: false  # Enable for production environments

  # Ingress rules (incoming traffic)
  ingress:
    - from: []  # Allow from any source (customize as needed)
      ports:
        - protocol: TCP
          port: 8081  # Health check port

  # Egress rules (outgoing traffic)
  egress:
    # Allow Kubernetes API access
    - to:
        - namespaceSelector:
            matchLabels:
              name: kube-system
      ports:
        - protocol: TCP
          port: 443

    # Allow Black Duck server access
    - to: []  # Customize with specific server endpoints
      ports:
        - protocol: TCP
          port: 443
        - protocol: TCP
          port: 80

    # Allow container registry access
    - to: []
      ports:
        - protocol: TCP
          port: 443
        - protocol: TCP
          port: 80

    # DNS resolution
    - to: []
      ports:
        - protocol: UDP
          port: 53

# Pod Security Standards compliance
podSecurityStandards:
  enforce: "baseline"  # baseline, restricted, privileged
  audit: "restricted"
  warn: "restricted"

  # Custom pod security policy (if needed)
  customPodSecurityPolicy:
    enabled: false
    name: "bd-selfscan-psp"

# Advanced configuration
advanced:
  # Custom environment variables
  extraEnvVars: []
  # - name: CUSTOM_VAR
  #   value: "custom-value"

  # Additional volumes
  extraVolumes: []
  # - name: custom-config
  #   configMap:
  #     name: custom-config-map

  # Additional volume mounts
  extraVolumeMounts: []
  # - name: custom-config
  #   mountPath: /etc/custom
  #   readOnly: true

  # Custom annotations
  podAnnotations: {}
  # annotation-key: "annotation-value"

  # Priority class for pod scheduling
  priorityClassName: ""
  # priorityClassName: "high-priority"

  # Pod disruption budget
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    # maxUnavailable: 1

# Backup and disaster recovery
backup:
  enabled: false
  schedule: "0 2 * * *"  # Daily at 2 AM
  retention: "7d"

  # Configuration backup
  configBackup:
    enabled: true
    includeSecrets: false  # Don't backup secrets for security

  # Results backup (to external storage)
  resultsBackup:
    enabled: false
    storage:
      type: "s3"  # s3, gcs, azure
      bucket: ""
      prefix: "bd-selfscan-backups/"

# Testing and validation
testing:
  enabled: false

  # Test configuration validation
  validateConfig: true
  validateConnectivity: true
  validatePermissions: true

  # Load testing
  loadTest:
    enabled: false
    concurrentScans: 5
    testDuration: "10m"

# Security context profiles for different environments
securityProfiles:
  # Development profile - more permissive for troubleshooting
  development:
    job:
      securityContext:
        runAsNonRoot: false
        runAsUser: 0
        runAsGroup: 0
        fsGroup: 0
    container:
      securityContext:
        allowPrivilegeEscalation: true
        readOnlyRootFilesystem: false
        runAsUser: 0
        capabilities:
          drop: ["ALL"]
          add: ["CHOWN", "DAC_OVERRIDE", "FOWNER", "SETGID", "SETUID"]

  # Production profile - enhanced security where possible
  production:
    job:
      securityContext:
        runAsNonRoot: false  # Still false due to BD requirements
        runAsUser: 0
        runAsGroup: 0
        fsGroup: 0
        seccompProfile:
          type: RuntimeDefault
    container:
      securityContext:
        allowPrivilegeEscalation: true  # Required for BD
        readOnlyRootFilesystem: false   # Required for BD
        runAsUser: 0
        capabilities:
          drop: ["ALL"]
          add: ["DAC_OVERRIDE", "FOWNER"]  # Minimal set

# External Secrets Operator Integration
# Supports: AWS Secrets Manager, HashiCorp Vault, Azure Key Vault, GCP Secret Manager
externalSecrets:
  enabled: false
  # Secret store reference (must be pre-configured in your cluster)
  secretStoreRef:
    name: "cluster-secret-store"
    kind: "ClusterSecretStore"  # or "SecretStore" for namespace-scoped
  # Refresh interval for secret synchronization
  refreshInterval: "1h"
  # Provider-specific configuration
  provider: "vault"  # Options: vault, aws, azure, gcp
  
  # HashiCorp Vault configuration
  vault:
    path: "secret/data/bd-selfscan/blackduck"
  
  # AWS Secrets Manager configuration
  aws:
    secretName: "bd-selfscan/blackduck-credentials"
    region: "us-east-1"
  
  # Azure Key Vault configuration
  azure:
    urlSecretName: "blackduck-url"
    tokenSecretName: "blackduck-token"
  
  # GCP Secret Manager configuration
  gcp:
    urlSecretName: "blackduck-url"
    tokenSecretName: "blackduck-token"
    projectId: ""

# Notification Configuration
# Supports: Slack, Microsoft Teams, Generic Webhooks
notifications:
  enabled: false
  
  # When to send notifications
  onSuccess: false
  onFailure: true
  onPolicyViolation: true
  
  # Slack configuration
  slack:
    enabled: false
    # Webhook URL (can also be provided via secret)
    webhookUrl: ""
    # Or reference a secret containing the webhook URL
    webhookSecretRef:
      name: ""
      key: "webhook-url"
    channel: "#security-alerts"
    username: "BD SelfScan"
  
  # Microsoft Teams configuration
  teams:
    enabled: false
    webhookUrl: ""
    webhookSecretRef:
      name: ""
      key: "webhook-url"
  
  # Generic webhook configuration (for custom integrations)
  genericWebhook:
    enabled: false
    url: ""
    secretRef:
      name: ""
      key: "webhook-url"
    # Custom headers (optional)
    headers: {}
    # headers:
    #   Authorization: "Bearer ${TOKEN}"
    #   X-Custom-Header: "value"

# GitOps Integration
# Supports: ArgoCD, Flux
gitops:
  # ArgoCD integration
  argocd:
    enabled: false
    # Enable ArgoCD notification templates
    notifications: true
    # Sync wave for scan jobs (run after deployment)
    syncWave: "10"
    # Hook configuration
    hook: "PostSync"
    hookDeletePolicy: "HookSucceeded"
  
  # Flux integration
  flux:
    enabled: false
    # Slack notifications via Flux
    slack:
      channel: "security-alerts"
      secretRef: "flux-slack-webhook"
    # Teams notifications via Flux
    teams:
      enabled: false
      secretRef: "flux-teams-webhook"
    # Alert filters (exclude certain events)
    alertFilters: []
    # - ".*test.*"
    # Image automation (auto-update scanner image)
    imageAutomation:
      enabled: false
      interval: "1h"
      secretRef: ""

# Troubleshooting helpers
troubleshooting:
  # Enable debug pod for testing
  debugPod:
    enabled: false
    image: "ghcr.io/snps-steve/bd-selfscan/bd-selfscan:latest"
    command: ["/bin/bash", "-c", "sleep 3600"]

  # Log aggregation
  logCollection:
    enabled: true
    retention: "7d"

# Per-Application Policy Gating Documentation:
#
# POLICY GATING OVERVIEW:
# BD SelfScan now supports per-application policy enforcement via the applications.yaml configuration.
# This allows different applications to have different security requirements while maintaining 
# a single scanning infrastructure.
#
# CONFIGURATION FIELDS (in applications.yaml):
#   policyGating: true/false         - Enable/disable policy enforcement for this application
#   policyGatingRisk: "BLOCKER,..."  - Comma-separated severity levels that cause failures
#
# ENFORCEMENT MODES:
#   Discovery Mode (policyGating: false):
#     - Scans always succeed regardless of findings
#     - All vulnerabilities reported to Black Duck for visibility
#     - Perfect for legacy systems, testing, or initial rollout
#   
#   Enforcement Mode (policyGating: true):
#     - Scans can fail on policy violations
#     - Build/deployment blocked when violations found
#     - Granular control via policyGatingRisk setting
#
# POLICY SEVERITY LEVELS:
#   BLOCKER   - Must fix immediately (all tiers should include)
#   CRITICAL  - High-severity vulnerabilities (tier 1-3)
#   HIGH      - Important security issues (tier 1-2)
#   MEDIUM    - Moderate concerns (tier 1 only)
#   LOW       - Minor issues (rarely used for blocking)
#   TRIVIAL   - Informational (rarely used for blocking)
#
# RECOMMENDED CONFIGURATIONS BY TIER:
#   Tier 1 (Critical):    policyGating: true, policyGatingRisk: "BLOCKER,CRITICAL,HIGH"
#   Tier 2 (High):        policyGating: true, policyGatingRisk: "BLOCKER,CRITICAL"  
#   Tier 3 (Medium):      policyGating: true, policyGatingRisk: "BLOCKER,CRITICAL"
#   Tier 4 (Low):         policyGating: false (discovery mode)
#
# MIGRATION STRATEGY:
#   Week 1-2: All applications with policyGating: false (discovery mode)
#   Week 3-4: Non-critical apps with policyGating: true, policyGatingRisk: "BLOCKER"
#   Week 5+:  Gradually tighten policies based on application criticality
#
# EXAMPLE CONFIGURATION:
# applications:
#   - name: "Payment API"
#     namespace: "payments"
#     labelSelector: "app=payment-api"
#     policyGating: true                    # Enable enforcement
#     policyGatingRisk: "BLOCKER,CRITICAL" # Block on these severities
#     projectGroup: "Financial Services"
#     projectTier: 1
#     description: "Critical payment processing with strict enforcement"
#   
#   - name: "Admin Tools"
#     namespace: "admin"
#     labelSelector: "app=admin-dashboard"
#     policyGating: false                   # Discovery mode
#     policyGatingRisk: ""                  # Ignored when gating disabled
#     projectGroup: "Internal Tools"
#     projectTier: 4
#     description: "Internal tools in discovery mode"
#
# TESTING COMMANDS:
#   kubectl exec -it <pod> -- /scripts/test-policy-gating.sh
#   kubectl exec -it <pod> -- /scripts/simulate-policy-enforcement.sh "App Name" critical
#   kubectl exec -it <pod> -- /scripts/policy-gating-preview.sh
